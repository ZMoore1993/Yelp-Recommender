# CptS315-project

NOTE: THE PROGRAM ALONE DOESN'T WORK; IT NEEDS THE DATASET FROM YELP AND IT'S MUCH TOO LARGE TO PUT ON GIT FOR RIGHT NOW.

This project uses data from Yelp that has businesses and their ratings from users. My motivation behind choosing this task is wanting to use some of the algorithms learned in class and machine learning tool kits by using a dataset I used in a previous class. One thing I would like to know is how many businesses have at least one review. I would like to try recommend a couple restaurants that a user hasn’t rated for a number of users. 

The source of my data is the dataset (link) provided by Yelp for their dataset challenge. I will just be using the dataset for the class project and not actually doing the challenge. The dataset is quite large so I would reduce the amount of data in order to not waste time with waiting for the program to finish.

For the algorithms (such as the recommender) we learned in class, I would build my own programs for the algorithms. I might try to compare them to the algorithms in the scikit-learn tool kit. For the number of businesses that have ratings, I will use graphs to show the percentage of businesses that have a certain rating in increments. For example, I would make a graph for percentage of businesses with a 1 star rating or higher. Then I would make a graph for the percentage with a 2 star rating or higher. This would continue to the maximum ratings level.
The graphs would be made from scikit-learn tool kit as well. I would like to use Jupyter Notebook to make final report since it run Python code inside the file.

The final product will be a Jupyter Notebook file that has the code, in different sections, as part of the final report. If that doesn’t work, then each algorithm would be its own program in order to increase readability and reduce program file size. I would measure the success of my project by how well the algorithms run correctly and accurately.
